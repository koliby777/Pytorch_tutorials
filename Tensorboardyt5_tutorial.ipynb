{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koliby777/Pytorch_tutorials/blob/main/Tensorboardyt5_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2mad09mhlT5"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "525dNERQhlT7"
      },
      "source": [
        "[Introduction](introyt1_tutorial.html) \\|\\|\n",
        "[Tensors](tensors_deeper_tutorial.html) \\|\\|\n",
        "[Autograd](autogradyt_tutorial.html) \\|\\| [Building\n",
        "Models](modelsyt_tutorial.html) \\|\\| **TensorBoard Support** \\|\\|\n",
        "[Training Models](trainingyt.html) \\|\\| [Model\n",
        "Understanding](captumyt.html)\n",
        "\n",
        "PyTorch TensorBoard Support\n",
        "===========================\n",
        "\n",
        "Follow along with the video below or on\n",
        "[youtube](https://www.youtube.com/watch?v=6CEld3hZgqc).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ...... je to ad obrazky atd.............."
      ],
      "metadata": {
        "id": "QbFUYRbDaIn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d8539f5"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load the video\n",
        "from IPython.display import display, HTML\n",
        "html_code = \"\"\"\n",
        "<div style=\"margin-top:10px; margin-bottom:10px;\">\n",
        "  <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6CEld3hZgqc\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
        "</div>\n",
        "\"\"\"\n",
        "display(HTML(html_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78de5aa6"
      },
      "source": [
        "\n",
        "\n",
        "Before You Start\n",
        "----------------\n",
        "\n",
        "To run this tutorial, you'll need to install PyTorch, TorchVision,\n",
        "Matplotlib, and TensorBoard.\n",
        "\n",
        "With `conda`:\n",
        "\n",
        "``` {.sourceCode .sh}\n",
        "conda install pytorch torchvision -c pytorch\n",
        "conda install matplotlib tensorboard\n",
        "```\n",
        "\n",
        "With `pip`:\n",
        "\n",
        "``` {.sourceCode .sh}\n",
        "pip install torch torchvision matplotlib tensorboard\n",
        "```\n",
        "\n",
        "Once the dependencies are installed, restart this notebook in the Python\n",
        "environment where you installed them.\n",
        "\n",
        "Introduction\n",
        "------------\n",
        "\n",
        "In this notebook, we'll be training a variant of LeNet-5 against the\n",
        "Fashion-MNIST dataset. Fashion-MNIST is a set of image tiles depicting\n",
        "various garments, with ten class labels indicating the type of garment\n",
        "depicted.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision matplotlib tensorboard"
      ],
      "metadata": {
        "id": "2uAURv1shwaQ",
        "outputId": "c8281baa-a83b-4171-93ec-e97f72186f80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhFCHgE4hlT9"
      },
      "outputs": [],
      "source": [
        "# PyTorch model and training necessities\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Image datasets and image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Image display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# In case you are using an environment that has TensorFlow installed,\n",
        "# such as Google Colab, uncomment the following code to avoid\n",
        "# a bug with saving embeddings to your TensorBoard directory\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kGHvOHqhlT9"
      },
      "source": [
        "Showing Images in TensorBoard\n",
        "=============================\n",
        "\n",
        "Let's start by adding sample images from our dataset to TensorBoard:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9yOmXnohlT9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "42919ab3-db62-42b1-a153-4ca652c75e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 18560088.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 304037.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5477905.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 17655173.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Gather datasets and prepare them for consumption\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Store separate training and validations splits in ./data\n",
        "training_set = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transform)\n",
        "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transform)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set,\n",
        "                                              batch_size=4,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=2)\n",
        "\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
        "                                                batch_size=4,\n",
        "                                                shuffle=False,\n",
        "                                                num_workers=2)\n",
        "\n",
        "# Class labels\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# Helper function for inline image display\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "# Extract a batch of 4 images\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Create a grid from the images and show them\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb6J_ppFhlT-"
      },
      "source": [
        "Above, we used TorchVision and Matplotlib to create a visual grid of a\n",
        "minibatch of our input data. Below, we use the `add_image()` call on\n",
        "`SummaryWriter` to log the image for consumption by TensorBoard, and we\n",
        "also call `flush()` to make sure it's written to disk right away.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d69PZkKhlT-"
      },
      "outputs": [],
      "source": [
        "# Default log_dir argument is \"runs\" - but it's good to be specific\n",
        "# torch.utils.tensorboard.SummaryWriter is imported above\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
        "\n",
        "# Write image data to TensorBoard log dir\n",
        "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
        "writer.flush()\n",
        "\n",
        "# To view, start TensorBoard on the command line with:\n",
        "#   tensorboard --logdir=runs\n",
        "# ...and open a browser tab to http://localhost:6006/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSxmAychhlT-"
      },
      "source": [
        "If you start TensorBoard at the command line and open it in a new\n",
        "browser tab (usually at [localhost:6006](localhost:6006)), you should\n",
        "see the image grid under the IMAGES tab.\n",
        "\n",
        "Graphing Scalars to Visualize Training\n",
        "======================================\n",
        "\n",
        "TensorBoard is useful for tracking the progress and efficacy of your\n",
        "training. Below, we'll run a training loop, track some metrics, and save\n",
        "the data for TensorBoard's consumption.\n",
        "\n",
        "Let's define a model to categorize our image tiles, and an optimizer and\n",
        "loss function for training:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt6k8Gf7hlT-"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moyOYGTUhlT_"
      },
      "source": [
        "Now let's train a single epoch, and evaluate the training vs. validation\n",
        "set losses every 1000 batches:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bire0bfnhlT_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "6c6ba75c-6823-4804-f08e-47fbe4a17e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n",
            "Batch 1000\n",
            "Batch 2000\n",
            "Batch 3000\n",
            "Batch 4000\n",
            "Batch 5000\n",
            "Batch 6000\n",
            "Batch 7000\n",
            "Batch 8000\n",
            "Batch 9000\n",
            "Batch 10000\n",
            "Batch 11000\n",
            "Batch 12000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-eddc82b4f8e7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# basic training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    750\u001b[0m         raise ValueError(\n\u001b[1;32m    751\u001b[0m             \"Authkey must be bytes, not {0!s}\".format(type(authkey)))\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHALLENGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(len(validation_loader))\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(training_loader, 0):\n",
        "        # basic training loop\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # Every 1000 mini-batches...\n",
        "            print('Batch {}'.format(i + 1))\n",
        "            # Check against the validation set\n",
        "            running_vloss = 0.0\n",
        "\n",
        "            # In evaluation mode some model specific operations can be omitted eg. dropout layer\n",
        "            net.train(False) # Switching to evaluation mode, eg. turning off regularisation\n",
        "            for j, vdata in enumerate(validation_loader, 0):\n",
        "                vinputs, vlabels = vdata\n",
        "                voutputs = net(vinputs)\n",
        "                vloss = criterion(voutputs, vlabels)\n",
        "                running_vloss += vloss.item()\n",
        "            net.train(True) # Switching back to training mode, eg. turning on regularisation\n",
        "\n",
        "            avg_loss = running_loss / 1000\n",
        "            avg_vloss = running_vloss / len(validation_loader)\n",
        "\n",
        "            # Log the running loss averaged per batch\n",
        "            writer.add_scalars('Training vs. Validation Loss',\n",
        "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                            epoch * len(training_loader) + i)\n",
        "\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')\n",
        "\n",
        "writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUoLt9eFhlT_"
      },
      "source": [
        "Switch to your open TensorBoard and have a look at the SCALARS tab.\n",
        "\n",
        "Visualizing Your Model\n",
        "======================\n",
        "\n",
        "TensorBoard can also be used to examine the data flow within your model.\n",
        "To do this, call the `add_graph()` method with a model and sample input:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmJpmsaBhlT_"
      },
      "outputs": [],
      "source": [
        "# Again, grab a single mini-batch of images\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# add_graph() will trace the sample input through your model,\n",
        "# and render it as a graph.\n",
        "writer.add_graph(net, images)\n",
        "writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH_O0oVzhlT_"
      },
      "source": [
        "When you switch over to TensorBoard, you should see a GRAPHS tab.\n",
        "Double-click the \"NET\" node to see the layers and data flow within your\n",
        "model.\n",
        "\n",
        "Visualizing Your Dataset with Embeddings\n",
        "========================================\n",
        "\n",
        "The 28-by-28 image tiles we're using can be modeled as 784-dimensional\n",
        "vectors (28 \\* 28 = 784). It can be instructive to project this to a\n",
        "lower-dimensional representation. The `add_embedding()` method will\n",
        "project a set of data onto the three dimensions with highest variance,\n",
        "and display them as an interactive 3D chart. The `add_embedding()`\n",
        "method does this automatically by projecting to the three dimensions\n",
        "with highest variance.\n",
        "\n",
        "Below, we'll take a sample of our data, and generate such an embedding:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44N9c5dWhlT_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "99204c67-88a0-474c-b305-a811111a7584"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorboard.compat.tensorflow_stub.io.gfile' has no attribute 'join'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cff6eb059fb9>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# log embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m writer.add_embedding(features,\n\u001b[0m\u001b[1;32m     17\u001b[0m                     \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     label_img=images.unsqueeze(1))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_embedding\u001b[0;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001b[0m\n\u001b[1;32m    990\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m             ), \"#labels should equal with #data points\"\n\u001b[0;32m--> 992\u001b[0;31m             \u001b[0mmake_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\u001b[0m in \u001b[0;36mmake_tsv\u001b[0;34m(metadata, save_path, metadata_header)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmetadata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_gfile_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"metadata.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\u001b[0m in \u001b[0;36m_gfile_join\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# We need to try both because `tf` may point to either the stub or the real TF.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_GFILE_JOIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorboard.compat.tensorflow_stub.io.gfile' has no attribute 'join'"
          ]
        }
      ],
      "source": [
        "# Select a random subset of data and corresponding labels\n",
        "def select_n_random(data, labels, n=100):\n",
        "    assert len(data) == len(labels)\n",
        "\n",
        "    perm = torch.randperm(len(data))\n",
        "    return data[perm][:n], labels[perm][:n]\n",
        "\n",
        "# Extract a random subset of data\n",
        "images, labels = select_n_random(training_set.data, training_set.targets)\n",
        "\n",
        "# get the class labels for each image\n",
        "class_labels = [classes[label] for label in labels]\n",
        "\n",
        "# log embeddings\n",
        "features = images.view(-1, 28 * 28)\n",
        "writer.add_embedding(features,\n",
        "                    metadata=class_labels,\n",
        "                    label_img=images.unsqueeze(1))\n",
        "writer.flush()\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFAPY3aVhlT_"
      },
      "source": [
        "Now if you switch to TensorBoard and select the PROJECTOR tab, you\n",
        "should see a 3D representation of the projection. You can rotate and\n",
        "zoom the model. Examine it at large and small scales, and see whether\n",
        "you can spot patterns in the projected data and the clustering of\n",
        "labels.\n",
        "\n",
        "For better visibility, it's recommended to:\n",
        "\n",
        "-   Select \"label\" from the \"Color by\" drop-down on the left.\n",
        "-   Toggle the Night Mode icon along the top to place the light-colored\n",
        "    images on a dark background.\n",
        "\n",
        "Other Resources\n",
        "===============\n",
        "\n",
        "For more information, have a look at:\n",
        "\n",
        "-   PyTorch documentation on\n",
        "    [torch.utils.tensorboard.SummaryWriter](https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter)\n",
        "-   Tensorboard tutorial content in the [PyTorch.org\n",
        "    Tutorials](https://pytorch.org/tutorials/)\n",
        "-   For more information about TensorBoard, see the [TensorBoard\n",
        "    documentation](https://www.tensorflow.org/tensorboard)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}